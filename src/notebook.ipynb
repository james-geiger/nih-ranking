{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain\n",
    "import openpyxl\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "from chardet.universaldetector import UniversalDetector\n",
    "import requests\n",
    "import hashlib\n",
    "import io\n",
    "import warnings\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fileinfo = namedtuple('Fileinfo', ['delimiter', 'encoding'])\n",
    "\n",
    "class Sha256Mismatch(Exception):\n",
    "    pass\n",
    "\n",
    "class DataFile:\n",
    "    def __init__(\n",
    "            self,\n",
    "            file,\n",
    "            filename = None,\n",
    "            sha_integrity:Literal['strict', 'check', 'ignore'] = 'strict',\n",
    "            column_integrity:Literal['strict', 'check', 'ignore'] = 'strict'\n",
    "            ):\n",
    "        \n",
    "        if sha_integrity not in ['strict', 'check', 'ignore']:\n",
    "            raise AttributeError(\"The `sha_integrity` parameter must be specified as either 'strict', 'check', or 'ignore'.\")\n",
    "        if column_integrity not in ['strict', 'check', 'ignore']:\n",
    "            raise AttributeError(\"The `sha_integrity` parameter must be specified as either 'strict', 'check', or 'ignore'.\")\n",
    "        if type(file) not in [pd.DataFrame, str]:\n",
    "            raise AttributeError(\"The `file` parameter must be a Pandas DataFrame or a valid filepath that can be read into a DataFrame.\")\n",
    "        if type(file) == pd.DataFrame & type(filename) == None:\n",
    "            raise AttributeError(\"When `file` is a Pandas DataFrame you must also supply a filename.\")\n",
    "        \n",
    "        if type(file) == pd.DataFrame:\n",
    "            self.DataFrame = file\n",
    "            self.Filename = filename\n",
    "        elif type(file) == str:\n",
    "            self.Filename = file\n",
    "            self.read(file)\n",
    "\n",
    "        if sha_integrity == 'strict':\n",
    "            self.ensure_sha256_match()\n",
    "        elif sha_integrity == 'check':\n",
    "            self.ensure_sha256_match(strict=False)\n",
    "\n",
    "        if column_integrity == 'strict':\n",
    "            self.ensure_column_integrity()\n",
    "        elif column_integrity == 'check':\n",
    "            self.ensure_column_integrity(strict=False)\n",
    "\n",
    "    def read(self, filename:str) -> None:\n",
    "        self.DataFrame = pd.read_excel(filename)\n",
    "\n",
    "    def get_file_encoding(self, file_path: str) -> str:\n",
    "        detector = UniversalDetector()\n",
    "        for line in open(file_path, 'rb'):\n",
    "            detector.feed(line)\n",
    "            if detector.done: break\n",
    "        detector.close()\n",
    "        result = detector.result['encoding']\n",
    "        return result\n",
    "\n",
    "    def get_file_delimiter(self, file_path: str, encoding: str) -> str:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            delimiter = str(csv.Sniffer().sniff(file.read()).delimiter)\n",
    "\n",
    "    def get_file_info(self, file_path: str) -> namedtuple:\n",
    "        encoding = self.get_file_encoding(file_path)\n",
    "        delimiter = self.get_file_delimiter(file_path, encoding)\n",
    "        return Fileinfo(delimiter, encoding)\n",
    "    \n",
    "    def ensure_sha256_match(self, strict:bool = True) -> bool:\n",
    "        file = self.filename.split('/')[-1]\n",
    "\n",
    "        # GET the file from NIH RePORT\n",
    "        url = \"https://report.nih.gov/award/files/\" + file\n",
    "        session = requests.session()\n",
    "        response = session.get(url, stream=True)\n",
    "        nih_file = io.BytesIO(response.content)\n",
    "        nih_digest = hashlib.file_digest(nih_file, \"sha256\")\n",
    "\n",
    "        # Create hash for local file (in repository)\n",
    "        with open(self.filename, 'rb') as local_file:\n",
    "            local_digest = hashlib.file_digest(local_file, \"sha256\")\n",
    "\n",
    "        if strict and nih_digest.hexdigest() != local_digest.hexdigest() :\n",
    "            raise Sha256Mismatch(f'The local file {file} does not match the corresponding file downloaded from NIH.')\n",
    "        else:\n",
    "            # This will return True if the repository file exactly matches the file downloaded from NIH\n",
    "            return nih_digest.hexdigest() == local_digest.hexdigest()\n",
    "        \n",
    "    def ensure_column_integrity(self, strict:bool = True):\n",
    "        expected_columns = pd.Index(['ORGANIZATION NAME', 'ORGANIZATION ID (IPF)', 'PROJECT NUMBER',\n",
    "                                     'FUNDING MECHANISM', 'NIH REFERENCE', 'PI NAME', 'PI PERSON ID',\n",
    "                                     'PROJECT TITLE', 'DEPT NAME', 'NIH DEPT COMBINING NAME',\n",
    "                                     'NIH MC COMBINING NAME', 'DIRECT COST', 'INDIRECT COST', 'FUNDING',\n",
    "                                     'CONGRESSIONAL DISTRICT', 'CITY', 'STATE OR COUNTRY NAME', 'ZIP CODE',\n",
    "                                     'ATTRIBUTED TO MEDICAL SCHOOL', 'MEDICAL SCHOOL LOCATION',\n",
    "                                     'INSTITUTION TYPE', 'AWARD NOTICE DATE', 'OPPORTUNITY NUMBER'])\n",
    "        diff_columns = self.df.keys().difference(expected_columns)\n",
    "        column_errors = diff_columns.to_list()\n",
    "        error_string = ', '.join(column_errors)\n",
    "        if (len(column_errors) > 0) and strict:\n",
    "            error_values = self.df[[diff_columns.to_list()[0]]].dropna()\n",
    "            self.df.drop(index=error_values.index, inplace=True)\n",
    "            self.df.drop(columns=error_values, inplace=True)\n",
    "        elif (len(column_errors) > 0) and not(strict):\n",
    "            warnings.warn(f\"DataFile has extraneous columns: {error_string}\\n\\nThese are being ignored\", UserWarning)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "exts = [\".csv\", \".xls\", \".xlsx\", \".tsv\"]\n",
    "files = list(chain.from_iterable([glob.glob('./data/*' + ext) for ext in exts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/f36t65452jq_fxt8txzb439c0000gn/T/ipykernel_87784/1300396238.py:38: UserWarning: File has extraneous columns: Unnamed: 23\n",
      "  warnings.warn(f\"File has extraneous columns: {error_string}\", UserWarning)\n",
      "/var/folders/0g/f36t65452jq_fxt8txzb439c0000gn/T/ipykernel_87784/1300396238.py:38: UserWarning: File has extraneous columns: Unnamed: 23\n",
      "  warnings.warn(f\"File has extraneous columns: {error_string}\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse the file located at ./data/Worldwide2008.xls.  Will attempt automatic decoding...\n",
      "Automatic decoding succeeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/f36t65452jq_fxt8txzb439c0000gn/T/ipykernel_87784/1300396238.py:38: UserWarning: File has extraneous columns: Unnamed: 23\n",
      "  warnings.warn(f\"File has extraneous columns: {error_string}\", UserWarning)\n",
      "/var/folders/0g/f36t65452jq_fxt8txzb439c0000gn/T/ipykernel_87784/1300396238.py:38: UserWarning: File has extraneous columns: Unnamed: 23\n",
      "  warnings.warn(f\"File has extraneous columns: {error_string}\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse the file located at ./data/Worldwide2010.xls.  Will attempt automatic decoding...\n",
      "Automatic decoding succeeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/f36t65452jq_fxt8txzb439c0000gn/T/ipykernel_87784/1300396238.py:38: UserWarning: File has extraneous columns: Unnamed: 23\n",
      "  warnings.warn(f\"File has extraneous columns: {error_string}\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "failed = []\n",
    "\n",
    "for i in files:\n",
    "    try:\n",
    "        ensure_sha256_match(i)\n",
    "        df = pd.read_excel(i)\n",
    "        df['FILENAME'] = i\n",
    "        df = ensure_column_integrity(df)\n",
    "        data.append(df)\n",
    "    except Sha256Mismatch as e:\n",
    "        print(f'{e}\\n\\nExecution will stop.  Download the NIH file and replace locally before processing.')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to parse the file located at {i}.  Will attempt automatic decoding...')\n",
    "        try:\n",
    "            info = get_file_info(i)\n",
    "            df = pd.read_csv(i, sep=info.delimiter, encoding=info.encoding, engine=\"python\")\n",
    "            df['FILENAME'] = i\n",
    "            df = ensure_column_integrity(df)\n",
    "            data.append(df)\n",
    "            print('Automatic decoding succeeded.')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to automatically detect and parse the file located at {i}.\\n\\n{e}')\n",
    "            failed.append(i)\n",
    "            continue\n",
    "        continue\n",
    "\n",
    "all_fy = pd.concat(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
